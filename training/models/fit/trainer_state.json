{
  "best_global_step": 1100,
  "best_metric": 2.1850838661193848,
  "best_model_checkpoint": "../training/models/WellnessOne/checkpoint-1100",
  "epoch": 0.00841229418557521,
  "eval_steps": 50,
  "global_step": 1100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 7.647540168704736e-05,
      "grad_norm": 0.13804195821285248,
      "learning_rate": 1.3763572411683743e-06,
      "loss": 2.8566,
      "step": 10
    },
    {
      "epoch": 0.0001529508033740947,
      "grad_norm": 0.09992345422506332,
      "learning_rate": 2.9056430646887904e-06,
      "loss": 2.9211,
      "step": 20
    },
    {
      "epoch": 0.00022942620506114208,
      "grad_norm": 0.15030689537525177,
      "learning_rate": 4.434928888209206e-06,
      "loss": 3.0381,
      "step": 30
    },
    {
      "epoch": 0.0003059016067481894,
      "grad_norm": 0.1541035920381546,
      "learning_rate": 5.9642147117296224e-06,
      "loss": 2.7662,
      "step": 40
    },
    {
      "epoch": 0.0003823770084352368,
      "grad_norm": 0.12091860175132751,
      "learning_rate": 7.4935005352500385e-06,
      "loss": 2.6306,
      "step": 50
    },
    {
      "epoch": 0.0003823770084352368,
      "eval_loss": 2.8855466842651367,
      "eval_runtime": 5630.0436,
      "eval_samples_per_second": 11.613,
      "eval_steps_per_second": 5.806,
      "step": 50
    },
    {
      "epoch": 0.00045885241012228416,
      "grad_norm": 0.14550775289535522,
      "learning_rate": 9.022786358770454e-06,
      "loss": 2.8547,
      "step": 60
    },
    {
      "epoch": 0.0005353278118093315,
      "grad_norm": 0.1730286031961441,
      "learning_rate": 1.055207218229087e-05,
      "loss": 3.0311,
      "step": 70
    },
    {
      "epoch": 0.0006118032134963788,
      "grad_norm": 0.2114441990852356,
      "learning_rate": 1.2081358005811286e-05,
      "loss": 3.0526,
      "step": 80
    },
    {
      "epoch": 0.0006882786151834263,
      "grad_norm": 0.2222888022661209,
      "learning_rate": 1.3610643829331703e-05,
      "loss": 2.8954,
      "step": 90
    },
    {
      "epoch": 0.0007647540168704736,
      "grad_norm": 0.24485796689987183,
      "learning_rate": 1.5139929652852118e-05,
      "loss": 3.1537,
      "step": 100
    },
    {
      "epoch": 0.0007647540168704736,
      "eval_loss": 2.8763539791107178,
      "eval_runtime": 5623.04,
      "eval_samples_per_second": 11.627,
      "eval_steps_per_second": 5.814,
      "step": 100
    },
    {
      "epoch": 0.000841229418557521,
      "grad_norm": 0.21584849059581757,
      "learning_rate": 1.6669215476372533e-05,
      "loss": 2.8291,
      "step": 110
    },
    {
      "epoch": 0.0009177048202445683,
      "grad_norm": 0.16680338978767395,
      "learning_rate": 1.819850129989295e-05,
      "loss": 2.797,
      "step": 120
    },
    {
      "epoch": 0.0009941802219316158,
      "grad_norm": 0.1941840797662735,
      "learning_rate": 1.9727787123413367e-05,
      "loss": 2.949,
      "step": 130
    },
    {
      "epoch": 0.001070655623618663,
      "grad_norm": 0.39987850189208984,
      "learning_rate": 2.1257072946933785e-05,
      "loss": 2.7353,
      "step": 140
    },
    {
      "epoch": 0.0011471310253057105,
      "grad_norm": 0.43727684020996094,
      "learning_rate": 2.2786358770454197e-05,
      "loss": 2.8176,
      "step": 150
    },
    {
      "epoch": 0.0011471310253057105,
      "eval_loss": 2.8425912857055664,
      "eval_runtime": 5619.9765,
      "eval_samples_per_second": 11.634,
      "eval_steps_per_second": 5.817,
      "step": 150
    },
    {
      "epoch": 0.0012236064269927577,
      "grad_norm": 0.257520854473114,
      "learning_rate": 2.4315644593974612e-05,
      "loss": 3.0374,
      "step": 160
    },
    {
      "epoch": 0.0013000818286798051,
      "grad_norm": 0.3268379271030426,
      "learning_rate": 2.584493041749503e-05,
      "loss": 2.8936,
      "step": 170
    },
    {
      "epoch": 0.0013765572303668526,
      "grad_norm": 0.266009658575058,
      "learning_rate": 2.7374216241015446e-05,
      "loss": 2.9859,
      "step": 180
    },
    {
      "epoch": 0.0014530326320538998,
      "grad_norm": 0.21815937757492065,
      "learning_rate": 2.890350206453586e-05,
      "loss": 2.8373,
      "step": 190
    },
    {
      "epoch": 0.0015295080337409473,
      "grad_norm": 0.4424067735671997,
      "learning_rate": 3.0432787888056276e-05,
      "loss": 2.923,
      "step": 200
    },
    {
      "epoch": 0.0015295080337409473,
      "eval_loss": 2.7751166820526123,
      "eval_runtime": 5622.3136,
      "eval_samples_per_second": 11.629,
      "eval_steps_per_second": 5.814,
      "step": 200
    },
    {
      "epoch": 0.0016059834354279945,
      "grad_norm": 0.36051711440086365,
      "learning_rate": 3.1962073711576695e-05,
      "loss": 2.7959,
      "step": 210
    },
    {
      "epoch": 0.001682458837115042,
      "grad_norm": 0.6275338530540466,
      "learning_rate": 3.349135953509711e-05,
      "loss": 2.8205,
      "step": 220
    },
    {
      "epoch": 0.0017589342388020894,
      "grad_norm": 0.42415666580200195,
      "learning_rate": 3.5020645358617525e-05,
      "loss": 2.6274,
      "step": 230
    },
    {
      "epoch": 0.0018354096404891366,
      "grad_norm": 0.42002302408218384,
      "learning_rate": 3.654993118213795e-05,
      "loss": 2.6071,
      "step": 240
    },
    {
      "epoch": 0.001911885042176184,
      "grad_norm": 0.3760163187980652,
      "learning_rate": 3.8079217005658356e-05,
      "loss": 2.5318,
      "step": 250
    },
    {
      "epoch": 0.001911885042176184,
      "eval_loss": 2.6716878414154053,
      "eval_runtime": 5625.5428,
      "eval_samples_per_second": 11.622,
      "eval_steps_per_second": 5.811,
      "step": 250
    },
    {
      "epoch": 0.0019883604438632315,
      "grad_norm": 0.5063014626502991,
      "learning_rate": 3.960850282917877e-05,
      "loss": 2.7622,
      "step": 260
    },
    {
      "epoch": 0.0020648358455502788,
      "grad_norm": 0.37877157330513,
      "learning_rate": 4.1137788652699186e-05,
      "loss": 2.4973,
      "step": 270
    },
    {
      "epoch": 0.002141311247237326,
      "grad_norm": 0.29905131459236145,
      "learning_rate": 4.266707447621961e-05,
      "loss": 2.6758,
      "step": 280
    },
    {
      "epoch": 0.0022177866489243737,
      "grad_norm": 0.5044481158256531,
      "learning_rate": 4.419636029974002e-05,
      "loss": 2.6806,
      "step": 290
    },
    {
      "epoch": 0.002294262050611421,
      "grad_norm": 0.22734816372394562,
      "learning_rate": 4.572564612326044e-05,
      "loss": 2.6222,
      "step": 300
    },
    {
      "epoch": 0.002294262050611421,
      "eval_loss": 2.572268486022949,
      "eval_runtime": 5627.2547,
      "eval_samples_per_second": 11.618,
      "eval_steps_per_second": 5.809,
      "step": 300
    },
    {
      "epoch": 0.002370737452298468,
      "grad_norm": 0.5650866031646729,
      "learning_rate": 4.7254931946780854e-05,
      "loss": 2.6017,
      "step": 310
    },
    {
      "epoch": 0.0024472128539855154,
      "grad_norm": 0.4218842685222626,
      "learning_rate": 4.8784217770301276e-05,
      "loss": 2.3432,
      "step": 320
    },
    {
      "epoch": 0.002523688255672563,
      "grad_norm": 0.4066402316093445,
      "learning_rate": 5.031350359382169e-05,
      "loss": 2.5743,
      "step": 330
    },
    {
      "epoch": 0.0026001636573596103,
      "grad_norm": 0.6161822080612183,
      "learning_rate": 5.18427894173421e-05,
      "loss": 2.3492,
      "step": 340
    },
    {
      "epoch": 0.0026766390590466575,
      "grad_norm": 0.40341702103614807,
      "learning_rate": 5.3372075240862514e-05,
      "loss": 2.4389,
      "step": 350
    },
    {
      "epoch": 0.0026766390590466575,
      "eval_loss": 2.469228506088257,
      "eval_runtime": 5619.3471,
      "eval_samples_per_second": 11.635,
      "eval_steps_per_second": 5.817,
      "step": 350
    },
    {
      "epoch": 0.002753114460733705,
      "grad_norm": 0.6013020277023315,
      "learning_rate": 5.4901361064382936e-05,
      "loss": 2.3627,
      "step": 360
    },
    {
      "epoch": 0.0028295898624207524,
      "grad_norm": 0.5692229270935059,
      "learning_rate": 5.643064688790335e-05,
      "loss": 2.478,
      "step": 370
    },
    {
      "epoch": 0.0029060652641077996,
      "grad_norm": 0.5069842338562012,
      "learning_rate": 5.7959932711423767e-05,
      "loss": 2.395,
      "step": 380
    },
    {
      "epoch": 0.002982540665794847,
      "grad_norm": 0.4052507281303406,
      "learning_rate": 5.948921853494418e-05,
      "loss": 2.3196,
      "step": 390
    },
    {
      "epoch": 0.0030590160674818945,
      "grad_norm": 0.5289690494537354,
      "learning_rate": 6.1018504358464604e-05,
      "loss": 2.2555,
      "step": 400
    },
    {
      "epoch": 0.0030590160674818945,
      "eval_loss": 2.3931500911712646,
      "eval_runtime": 5611.9748,
      "eval_samples_per_second": 11.65,
      "eval_steps_per_second": 5.825,
      "step": 400
    },
    {
      "epoch": 0.0031354914691689418,
      "grad_norm": 0.5150473117828369,
      "learning_rate": 6.254779018198501e-05,
      "loss": 2.2252,
      "step": 410
    },
    {
      "epoch": 0.003211966870855989,
      "grad_norm": 0.5825853943824768,
      "learning_rate": 6.407707600550543e-05,
      "loss": 2.4438,
      "step": 420
    },
    {
      "epoch": 0.0032884422725430367,
      "grad_norm": 0.5085365176200867,
      "learning_rate": 6.560636182902586e-05,
      "loss": 2.4603,
      "step": 430
    },
    {
      "epoch": 0.003364917674230084,
      "grad_norm": 0.37993523478507996,
      "learning_rate": 6.713564765254626e-05,
      "loss": 2.5378,
      "step": 440
    },
    {
      "epoch": 0.003441393075917131,
      "grad_norm": 0.4788036048412323,
      "learning_rate": 6.866493347606669e-05,
      "loss": 2.2745,
      "step": 450
    },
    {
      "epoch": 0.003441393075917131,
      "eval_loss": 2.343210458755493,
      "eval_runtime": 5612.4196,
      "eval_samples_per_second": 11.649,
      "eval_steps_per_second": 5.825,
      "step": 450
    },
    {
      "epoch": 0.003517868477604179,
      "grad_norm": 0.7867631912231445,
      "learning_rate": 7.019421929958709e-05,
      "loss": 2.5444,
      "step": 460
    },
    {
      "epoch": 0.003594343879291226,
      "grad_norm": 0.7536993622779846,
      "learning_rate": 7.17235051231075e-05,
      "loss": 2.3206,
      "step": 470
    },
    {
      "epoch": 0.0036708192809782733,
      "grad_norm": 0.6007593870162964,
      "learning_rate": 7.325279094662793e-05,
      "loss": 2.0937,
      "step": 480
    },
    {
      "epoch": 0.0037472946826653205,
      "grad_norm": 0.6168415546417236,
      "learning_rate": 7.478207677014833e-05,
      "loss": 2.2874,
      "step": 490
    },
    {
      "epoch": 0.003823770084352368,
      "grad_norm": 0.5923082232475281,
      "learning_rate": 7.631136259366876e-05,
      "loss": 2.3797,
      "step": 500
    },
    {
      "epoch": 0.003823770084352368,
      "eval_loss": 2.312396287918091,
      "eval_runtime": 5609.6794,
      "eval_samples_per_second": 11.655,
      "eval_steps_per_second": 5.827,
      "step": 500
    },
    {
      "epoch": 0.0039002454860394154,
      "grad_norm": 0.5203041434288025,
      "learning_rate": 7.784064841718918e-05,
      "loss": 2.5414,
      "step": 510
    },
    {
      "epoch": 0.003976720887726463,
      "grad_norm": 0.41515520215034485,
      "learning_rate": 7.936993424070959e-05,
      "loss": 2.4803,
      "step": 520
    },
    {
      "epoch": 0.00405319628941351,
      "grad_norm": 0.6732110381126404,
      "learning_rate": 8.089922006423001e-05,
      "loss": 2.0466,
      "step": 530
    },
    {
      "epoch": 0.0041296716911005575,
      "grad_norm": 0.4589746594429016,
      "learning_rate": 8.242850588775041e-05,
      "loss": 2.339,
      "step": 540
    },
    {
      "epoch": 0.004206147092787605,
      "grad_norm": 0.4125823676586151,
      "learning_rate": 8.395779171127084e-05,
      "loss": 2.2845,
      "step": 550
    },
    {
      "epoch": 0.004206147092787605,
      "eval_loss": 2.2889578342437744,
      "eval_runtime": 5614.8125,
      "eval_samples_per_second": 11.644,
      "eval_steps_per_second": 5.822,
      "step": 550
    },
    {
      "epoch": 0.004282622494474652,
      "grad_norm": 0.5781068801879883,
      "learning_rate": 8.548707753479125e-05,
      "loss": 2.1103,
      "step": 560
    },
    {
      "epoch": 0.0043590978961617,
      "grad_norm": 0.7239331007003784,
      "learning_rate": 8.701636335831167e-05,
      "loss": 2.4563,
      "step": 570
    },
    {
      "epoch": 0.004435573297848747,
      "grad_norm": 0.35074979066848755,
      "learning_rate": 8.854564918183208e-05,
      "loss": 2.5169,
      "step": 580
    },
    {
      "epoch": 0.004512048699535794,
      "grad_norm": 0.7270056009292603,
      "learning_rate": 9.007493500535251e-05,
      "loss": 2.2967,
      "step": 590
    },
    {
      "epoch": 0.004588524101222842,
      "grad_norm": 0.565333366394043,
      "learning_rate": 9.160422082887291e-05,
      "loss": 2.4105,
      "step": 600
    },
    {
      "epoch": 0.004588524101222842,
      "eval_loss": 2.2704429626464844,
      "eval_runtime": 5614.7786,
      "eval_samples_per_second": 11.644,
      "eval_steps_per_second": 5.822,
      "step": 600
    },
    {
      "epoch": 0.004664999502909889,
      "grad_norm": 0.7889375686645508,
      "learning_rate": 9.313350665239334e-05,
      "loss": 2.3001,
      "step": 610
    },
    {
      "epoch": 0.004741474904596936,
      "grad_norm": 0.6225262880325317,
      "learning_rate": 9.466279247591374e-05,
      "loss": 2.4076,
      "step": 620
    },
    {
      "epoch": 0.004817950306283984,
      "grad_norm": 0.6597639322280884,
      "learning_rate": 9.619207829943416e-05,
      "loss": 2.3899,
      "step": 630
    },
    {
      "epoch": 0.004894425707971031,
      "grad_norm": 0.4549511671066284,
      "learning_rate": 9.772136412295459e-05,
      "loss": 2.2919,
      "step": 640
    },
    {
      "epoch": 0.004970901109658078,
      "grad_norm": 0.685373842716217,
      "learning_rate": 9.925064994647499e-05,
      "loss": 2.3097,
      "step": 650
    },
    {
      "epoch": 0.004970901109658078,
      "eval_loss": 2.2558164596557617,
      "eval_runtime": 5614.4268,
      "eval_samples_per_second": 11.645,
      "eval_steps_per_second": 5.823,
      "step": 650
    },
    {
      "epoch": 0.005047376511345126,
      "grad_norm": 0.853773295879364,
      "learning_rate": 0.00010077993576999542,
      "loss": 2.1026,
      "step": 660
    },
    {
      "epoch": 0.005123851913032173,
      "grad_norm": 0.9502137899398804,
      "learning_rate": 0.00010230922159351583,
      "loss": 2.2009,
      "step": 670
    },
    {
      "epoch": 0.0052003273147192206,
      "grad_norm": 0.6318170428276062,
      "learning_rate": 0.00010383850741703625,
      "loss": 2.2193,
      "step": 680
    },
    {
      "epoch": 0.005276802716406268,
      "grad_norm": 0.7327162623405457,
      "learning_rate": 0.00010536779324055666,
      "loss": 2.2957,
      "step": 690
    },
    {
      "epoch": 0.005353278118093315,
      "grad_norm": 0.5007964372634888,
      "learning_rate": 0.00010689707906407708,
      "loss": 2.1691,
      "step": 700
    },
    {
      "epoch": 0.005353278118093315,
      "eval_loss": 2.244365692138672,
      "eval_runtime": 5617.9138,
      "eval_samples_per_second": 11.638,
      "eval_steps_per_second": 5.819,
      "step": 700
    },
    {
      "epoch": 0.005429753519780363,
      "grad_norm": 0.5140385031700134,
      "learning_rate": 0.0001084263648875975,
      "loss": 2.2779,
      "step": 710
    },
    {
      "epoch": 0.00550622892146741,
      "grad_norm": 0.5356816053390503,
      "learning_rate": 0.00010995565071111791,
      "loss": 2.1305,
      "step": 720
    },
    {
      "epoch": 0.005582704323154457,
      "grad_norm": 0.7918768525123596,
      "learning_rate": 0.00011148493653463833,
      "loss": 2.2074,
      "step": 730
    },
    {
      "epoch": 0.005659179724841505,
      "grad_norm": 0.40913131833076477,
      "learning_rate": 0.00011301422235815874,
      "loss": 2.2286,
      "step": 740
    },
    {
      "epoch": 0.0057356551265285525,
      "grad_norm": 0.4423430860042572,
      "learning_rate": 0.00011454350818167917,
      "loss": 2.3804,
      "step": 750
    },
    {
      "epoch": 0.0057356551265285525,
      "eval_loss": 2.23327374458313,
      "eval_runtime": 5612.4917,
      "eval_samples_per_second": 11.649,
      "eval_steps_per_second": 5.825,
      "step": 750
    },
    {
      "epoch": 0.005812130528215599,
      "grad_norm": 0.6670559048652649,
      "learning_rate": 0.00011607279400519957,
      "loss": 2.4118,
      "step": 760
    },
    {
      "epoch": 0.005888605929902647,
      "grad_norm": 0.7686358690261841,
      "learning_rate": 0.00011760207982872,
      "loss": 2.2268,
      "step": 770
    },
    {
      "epoch": 0.005965081331589694,
      "grad_norm": 0.5375663638114929,
      "learning_rate": 0.0001191313656522404,
      "loss": 2.336,
      "step": 780
    },
    {
      "epoch": 0.006041556733276741,
      "grad_norm": 0.6464686393737793,
      "learning_rate": 0.00012066065147576082,
      "loss": 2.2117,
      "step": 790
    },
    {
      "epoch": 0.006118032134963789,
      "grad_norm": 0.6750427484512329,
      "learning_rate": 0.00012218993729928124,
      "loss": 2.1915,
      "step": 800
    },
    {
      "epoch": 0.006118032134963789,
      "eval_loss": 2.2243528366088867,
      "eval_runtime": 5542.728,
      "eval_samples_per_second": 11.796,
      "eval_steps_per_second": 5.898,
      "step": 800
    },
    {
      "epoch": 0.006194507536650836,
      "grad_norm": 0.6454541683197021,
      "learning_rate": 0.00012371922312280165,
      "loss": 2.0604,
      "step": 810
    },
    {
      "epoch": 0.0062709829383378836,
      "grad_norm": 0.6496269106864929,
      "learning_rate": 0.00012524850894632205,
      "loss": 2.2095,
      "step": 820
    },
    {
      "epoch": 0.006347458340024931,
      "grad_norm": 0.597816526889801,
      "learning_rate": 0.0001267777947698425,
      "loss": 2.3212,
      "step": 830
    },
    {
      "epoch": 0.006423933741711978,
      "grad_norm": 1.0440630912780762,
      "learning_rate": 0.0001283070805933629,
      "loss": 2.1764,
      "step": 840
    },
    {
      "epoch": 0.006500409143399026,
      "grad_norm": 0.6033520698547363,
      "learning_rate": 0.0001298363664168833,
      "loss": 2.197,
      "step": 850
    },
    {
      "epoch": 0.006500409143399026,
      "eval_loss": 2.216228723526001,
      "eval_runtime": 5577.091,
      "eval_samples_per_second": 11.723,
      "eval_steps_per_second": 5.861,
      "step": 850
    },
    {
      "epoch": 0.006576884545086073,
      "grad_norm": 0.6769937872886658,
      "learning_rate": 0.00013136565224040374,
      "loss": 2.1022,
      "step": 860
    },
    {
      "epoch": 0.00665335994677312,
      "grad_norm": 0.9816999435424805,
      "learning_rate": 0.00013289493806392414,
      "loss": 2.1787,
      "step": 870
    },
    {
      "epoch": 0.006729835348460168,
      "grad_norm": 0.7993423342704773,
      "learning_rate": 0.00013442422388744457,
      "loss": 2.1153,
      "step": 880
    },
    {
      "epoch": 0.0068063107501472155,
      "grad_norm": 0.821990430355072,
      "learning_rate": 0.000135953509710965,
      "loss": 2.0114,
      "step": 890
    },
    {
      "epoch": 0.006882786151834262,
      "grad_norm": 0.6802924871444702,
      "learning_rate": 0.0001374827955344854,
      "loss": 2.0759,
      "step": 900
    },
    {
      "epoch": 0.006882786151834262,
      "eval_loss": 2.2079453468322754,
      "eval_runtime": 5513.3181,
      "eval_samples_per_second": 11.859,
      "eval_steps_per_second": 5.929,
      "step": 900
    },
    {
      "epoch": 0.00695926155352131,
      "grad_norm": 1.0017290115356445,
      "learning_rate": 0.0001390120813580058,
      "loss": 2.1474,
      "step": 910
    },
    {
      "epoch": 0.007035736955208358,
      "grad_norm": 0.829563558101654,
      "learning_rate": 0.00014054136718152625,
      "loss": 2.2314,
      "step": 920
    },
    {
      "epoch": 0.007112212356895404,
      "grad_norm": 0.4985685348510742,
      "learning_rate": 0.00014207065300504666,
      "loss": 1.9843,
      "step": 930
    },
    {
      "epoch": 0.007188687758582452,
      "grad_norm": 0.6197875738143921,
      "learning_rate": 0.00014359993882856706,
      "loss": 2.1344,
      "step": 940
    },
    {
      "epoch": 0.007265163160269499,
      "grad_norm": 0.7077996730804443,
      "learning_rate": 0.00014512922465208746,
      "loss": 2.015,
      "step": 950
    },
    {
      "epoch": 0.007265163160269499,
      "eval_loss": 2.2004449367523193,
      "eval_runtime": 5512.9915,
      "eval_samples_per_second": 11.859,
      "eval_steps_per_second": 5.93,
      "step": 950
    },
    {
      "epoch": 0.0073416385619565466,
      "grad_norm": 0.5923739671707153,
      "learning_rate": 0.0001466585104756079,
      "loss": 2.1044,
      "step": 960
    },
    {
      "epoch": 0.007418113963643594,
      "grad_norm": 0.5446722507476807,
      "learning_rate": 0.00014818779629912832,
      "loss": 2.212,
      "step": 970
    },
    {
      "epoch": 0.007494589365330641,
      "grad_norm": 0.5522702932357788,
      "learning_rate": 0.00014971708212264872,
      "loss": 2.2409,
      "step": 980
    },
    {
      "epoch": 0.007571064767017689,
      "grad_norm": 0.5014762878417969,
      "learning_rate": 0.00015124636794616915,
      "loss": 2.175,
      "step": 990
    },
    {
      "epoch": 0.007647540168704736,
      "grad_norm": 0.43866363167762756,
      "learning_rate": 0.00015277565376968955,
      "loss": 2.1685,
      "step": 1000
    },
    {
      "epoch": 0.007647540168704736,
      "eval_loss": 2.1939568519592285,
      "eval_runtime": 5513.0073,
      "eval_samples_per_second": 11.859,
      "eval_steps_per_second": 5.93,
      "step": 1000
    },
    {
      "epoch": 0.007724015570391783,
      "grad_norm": 0.8655406832695007,
      "learning_rate": 0.00015430493959320998,
      "loss": 2.4565,
      "step": 1010
    },
    {
      "epoch": 0.007800490972078831,
      "grad_norm": 0.6725188493728638,
      "learning_rate": 0.0001558342254167304,
      "loss": 2.2273,
      "step": 1020
    },
    {
      "epoch": 0.007876966373765878,
      "grad_norm": 0.5776472091674805,
      "learning_rate": 0.0001573635112402508,
      "loss": 2.2221,
      "step": 1030
    },
    {
      "epoch": 0.007953441775452926,
      "grad_norm": 0.6198141574859619,
      "learning_rate": 0.0001588927970637712,
      "loss": 2.0753,
      "step": 1040
    },
    {
      "epoch": 0.008029917177139972,
      "grad_norm": 0.6673675179481506,
      "learning_rate": 0.00016042208288729164,
      "loss": 2.062,
      "step": 1050
    },
    {
      "epoch": 0.008029917177139972,
      "eval_loss": 2.1887459754943848,
      "eval_runtime": 5513.1574,
      "eval_samples_per_second": 11.859,
      "eval_steps_per_second": 5.929,
      "step": 1050
    },
    {
      "epoch": 0.00810639257882702,
      "grad_norm": 0.8209403157234192,
      "learning_rate": 0.00016195136871081207,
      "loss": 2.1745,
      "step": 1060
    },
    {
      "epoch": 0.008182867980514067,
      "grad_norm": 0.6008124947547913,
      "learning_rate": 0.00016348065453433247,
      "loss": 2.2283,
      "step": 1070
    },
    {
      "epoch": 0.008259343382201115,
      "grad_norm": 0.6556588411331177,
      "learning_rate": 0.00016500994035785287,
      "loss": 2.3181,
      "step": 1080
    },
    {
      "epoch": 0.008335818783888163,
      "grad_norm": 0.5048927664756775,
      "learning_rate": 0.0001665392261813733,
      "loss": 2.1609,
      "step": 1090
    },
    {
      "epoch": 0.00841229418557521,
      "grad_norm": 0.6075648665428162,
      "learning_rate": 0.00016806851200489373,
      "loss": 2.1433,
      "step": 1100
    },
    {
      "epoch": 0.00841229418557521,
      "eval_loss": 2.1850838661193848,
      "eval_runtime": 5512.6953,
      "eval_samples_per_second": 11.86,
      "eval_steps_per_second": 5.93,
      "step": 1100
    }
  ],
  "logging_steps": 10,
  "max_steps": 130761,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.93551994454016e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
